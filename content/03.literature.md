## Overview of currently suggested coding practises for bioinformaticians ##

The current coding practices in the field of bioinformatics is extremely variable and depends on the background of individual scientists, the research field they are in and others.
It can be overviewed from two perspectives: how bioinformatics software products are evaluated and what coding guidelines and suggestions are currently available.
Already almost two decades ago, Diane F. Kelly wrote that scientific computations keep on being performed using error-prone development practices and reaching suboptimal solutions and poor software quality due to lack of appropriate software engineering practices [@doi:10.1109/MS.2007.155].
Since then, limitations and caveats of scientific software development practices and products has been surveyed and discussed by software engineering researchers [@doi:10.1016/j.jss.2020.110848; @doi:10.1109/SECSE.2009.5069155; @doi:10.1109/CSEET.2009.44; @doi:10.1145/1852786.1852802; @doi:10.1109/MIC.2014.88].
To increase the consistency in how bioinformaticians code and the quality of their code, data analysis and coding guidelines are fairly consistently published.
Furthermore, since bioinformaticians are often self-taught programmers and only a small fraction have formal training in computer science and software engineering, the online learning and support resources become vital.
These include blog posts from peers, open-source lecture materials from universities, forums or articles that propose guidelines on how to code or analyse data in a better way.
Therefore, the encouraged practices are plenty, however they vary a lot and do not necessarily include a consistent view of the mainstream software standards.

We selected articles which would be the entry point for bioinformatician who aim to improve their programming skills (**Supplementary Methods**, **Table 1**).
These papers focus on specific suggestions, often referred to as rules or “tips & tricks”, or they more broadly direct the readers towards good practices of coding, which are put together into guidelines.
While their targets are early career researchers with minimal coding experience (e.g. first time terminal users), they also encourage the usage of state-of-the-art software solutions (e.g. containers).
Therefore, the guidelines are often a mix of basic and advanced concepts, especially from the perspective of a standard computer science and software engineering curriculum.
The first impression **Table 1** might give is being intimidating due to the sheer amount of recommendations.
Many of these guidelines are struggling to establish themselves within the bioinformatics community [@doi:10.7717/peerj-cs.839].
This muddled transmission prompts us to re-think our strategies and methods to realize the effective adoption of these software engineering notions.
In the coming paragraphs we highlight some insights about reasons of limited adoption, as well as review some recommended concepts and practices that we leant and established within our group through team effort.

Updating development practices, or even gaining a good understanding of new concepts is not a trivial task.
Beyond understanding, Arvanitou et al. note that a scientific software developer, depending on the application of the software (e.g. whether it is a tool or a data analysis pipeline), needs to make choices among the good practices [@doi:10.1016/j.jss.2020.110848].
The authors argue that selection can be done via the prioritization of software quality attributes [@{https://iso25000.com/index.php/en/iso-25000-standards/iso-25010?limit=3%20}].
Due to the trade-offs between these attributes (e.g. performance vs security), priorities needs to be set for each software product.
However, bioinformaticians are rarely familiar with the meaning and importance of these attributes [@doi:10.1109/CSEET.2009.44, @doi:10.48550/arXiv.1804.01954; @doi:10.1109/MS.2008.85].
We list these attributes and provide short descriptions for them in the Supplementary Materials.
Some, such as functional suitability and performance are implicitly prioritized within bioinformatics.
Others, such as maintainability, portability, and reliability, are neglected in most bioinformatics endeavour.
Through implicit prioritization bioinformaticians develop all software as a prototype, even when the goal is to create a long-term product.
Therefore, we decided to set three target quality attributes as our learning goals that we have neglected in the past: reliability, performance, and extensibility (**Figure 1**).

The hardship of scientific software testing has been discussed in detail [@doi:10.48550/arXiv.1804.01954; @doi:10.1109/MS.2008.85; @doi:10.1109/MIC.2014.88].
Prof. Globe emphasized the importance of software testing with an analogy, comparing it to the importance of testing the functionality of a microscope, which is self-evident to all researchers [@doi:10.1109/MIC.2014.88].
Therefore, we decided to include this as one of our examples in the next section.
In a recent review paper [@doi:10.48550/arXiv.1804.01954] two key aspects of scientific software testing have been highlighted: the oracle problem and the cultural differences between scientists and software engineers.
First, software behaviour can be tested against an expected output, but often in science we use software to find new knowledge.
This results in an oracle problem, when scientists actually do not know *a priori* the exact output a software should give for a new input dataset, thus straight forward verification is impossible.
Second, according to the authors, scientists also view their scientific model and the implementation as a single entity.
Therefore, scientists tend to test the validity of the model but not verify the code which produces it.
Uncovered faults can and do lead to incorrect scientific insights as shown in multiple examples [@doi:10.1126/science.314.5807.1856].
In our sessions, we covered unit testing and discussed verification for scientific software (**Figure 1**).

Another insight is about the complexity of bioinformatics software.
In bioinformatics analysis it is common to combine the functionalities that are coming from various packages.
This has several implications [@doi:10.1371/journal.pcbi.1005412; @doi:10.1016/j.jss.2020.110848; @doi:10.1109/MIC.2014.88; @doi:10.1101/2022.03.10.483804], here we highlight a few of them.
First, over time the software becomes increasingly hard to maintain.
The complexity, size, age, and the change-proneness of a code heavily affect maintainability [@doi:10.1109/CSEET.2009.44].
However, as bioinformatics software developers view their code as "means to an end", they care less about the future of their software.
To address this question, we built a shared understanding of functions and modularization (**Figure 1**), and expect the members of our code reviews to organize their code into modules.
Second, package management (including versioning) is a crucial aspect to ensure not only maintenance, but also ease of development, reproducibility, and reusability.
Frameworks [@doi:10.12688/f1000research.29032.1; @doi:10.1038/nbt.3820] and package management solutions [@{https://www.anaconda.com/}; @{https://docs.docker.com/}; @{https://apptainer.org/}] are required to achieve these qualities.
Similarly to modularization, we first learnt about version control and container solutions (**Figure 1**), so that we can expect members to follow these practices.
Third, it is practically impossible to test all functionalities of all modules, and the combinations of various functionalities.
It is therefore instrumental that the developers of the modules are trustworthy and responsible in their development.
As a user, we should select well maintained and open source software, whenever possible.
We encourage contribution to open source code within our teams, and aim to add developer documentation to our own tools.

Finally, throughout our literature review we found only one instance of suggestions on how to code in a team setting and utilize multiple people's expertise on software development.
Often guidelines for starting bioinformaticians encourage reaching out to others, but mostly to seek help when encountering a problem with their code.
This could include consulting with colleagues, finding a mentor or participating in online communities (for example, Stack Overflow or Biostars) [@doi:10.1371/journal.pcbi.1008645].
However, it is still mainly focused on individual practices, does not involve peer-pressure, and insufficient to recognize unknown unknowns.
The one counter example is the Code Clubs described by Hagan et al. [@doi:10.1371/journal.pcbi.1008119].
In their research group, members are collectively engaged in software development through code reviews and pair coding and software engineering education through workshops or seminars [@doi:10.1371/journal.pcbi.1008119].
It is in contrary to software engineering-oriented literature, where the main focus is on practices when coding in a team [@https://faculty.washington.edu/ajko/books/cooperative-software-development; @doi:10.1007/s10664-012-9205-0].
Sharing your coding experience with others helps minimize the isolation, allows individuals to learn from their peers, helps to establish and maintain standards, and helps to write a better quality software.
We therefore established a learning club called software quality seminars, regular code reviews, and a resource sharing platform to foster team effort (**Figure 1**).

***Table 1:*** **Collection of recommendations for improving scientific software quality.** Some guidelines are more vague than others, they also have varied scope, and they target different stakeholders. Therefore, it may be hard to find individual responsibility and actionable points from the literature.
<table>
    <thead>
        <tr>
            <th>Category</th>
            <th>Recommendation</th>
            <th>References</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=3>Software development 101</td>
            <td>Sanity check on input parameters</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Do not hard-code changeable parameters and paths</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Do not require superuser privileges</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td rowspan=3>Advanced software development</td>
            <td>Usage of design patterns</td>
            <td>[@doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>Adoption of international best practice standards of software quality</td>
            <td>[@doi:10.5281/zenodo.1172970]</td>
        </tr>
        <tr>
            <td>Regular refactoring</td>
            <td>[@doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td rowspan=7>Software development process</td>
            <td>Continuous integration</td>
            <td>[@doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>Agile software development methodology</td>
            <td>[@doi:10.7717/peerj-cs.839; @doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>Educated choice of software development methodology</td>
            <td>[@doi:10.1109/CSEET.2009.44]</td>
        </tr>
        <tr>
            <td>Independent review of source code</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.1109/CSEET.2009.44; @doi:10.1109/MIC.2014.88]</td>
        </tr>
        <tr>
            <td>Code quality monitoring</td>
            <td>[@doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>Inclusion of appropriate license</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Cooperation between developers and users</td>
            <td>[@doi:10.5281/zenodo.1172970]</td>
        </tr>
        <tr>
            <td rowspan=4>Testing and validation</td>
            <td>Establish validation and acceptance procedures</td>
            <td>[@doi:10.5281/zenodo.1172970]</td>
        </tr>
        <tr>
            <td>Provide a small test set</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Standardized tests</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.7717/peerj-cs.839; @doi:10.1109/CSEET.2009.44; @doi:10.1371/journal.pcbi.1005412; @doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>Ensure reproducibility of results</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td rowspan=5>Reproducibility</td>
            <td>Standardized working environment and automation</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.7717/peerj-cs.839]</td>
        </tr>
        <tr>
            <td>Version control</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.7717/peerj-cs.839; @doi:10.1371/journal.pcbi.1005412; @doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>Rely on package managers</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Containerization for portability</td>
            <td>[@doi:10.7717/peerj-cs.839; @doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Tagging of software version for reproducibility</td>
            <td>[@doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td rowspan=3>Documentation</td>
            <td>User (and developer) documentation</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.7717/peerj-cs.839; @doi:10.1109/CSEET.2009.44; @doi:10.1371/journal.pcbi.1005412]</td>
        </tr>
        <tr>
            <td>Requirements gathering</td>
            <td>[@doi:10.7717/peerj-cs.839; @doi:10.1109/CSEET.2009.44]</td>
        </tr>
        <tr>
            <td>Description of the software version used, its configurations and parameters in publications</td>
            <td>[@doi:10.5281/zenodo.1172970]</td>
        </tr>
        <tr>
            <td rowspan=8>Community effort</td>
            <td>contribute to open-source development</td>
            <td>[@doi:10.1109/MIC.2014.88]</td>
        </tr>
        <tr>
            <td>reuse existing (reliable) software</td>
            <td>[@doi:10.1371/journal.pcbi.1005412; @doi:10.1016/j.jss.2020.110848]</td>
        </tr>
        <tr>
            <td>preferentially selecting freely available open-source software</td>
            <td>[@doi:10.5281/zenodo.1172970]</td>
        </tr>
        <tr>
            <td>Encourage user participation in the software development process</td>
            <td>[@doi:10.5281/zenodo.1172970]</td>
        </tr>
        <tr>
            <td>Recognition and assignment of adequate time for quality-assured development</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.1109/CSEET.2009.44]</td>
        </tr>
        <tr>
            <td>Recognition of software development as academic achievement</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.1109/MIC.2014.88]</td>
        </tr>
        <tr>
            <td>Support for developer community for long term maintenance (when applicable)</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.1109/MIC.2014.88]</td>
        </tr>
        <tr>
            <td>Financial support for software development and maintenance</td>
            <td>[@doi:10.5281/zenodo.1172970; @doi:10.1109/MIC.2014.88]</td>
        </tr>
    </tbody>
</table> 



![***Figure 1:*** **An illustration comparing the process of improvement in software writing to rock climbing.**
DSA: data structures and algorithms, OOP: object-oriented programming, UML: Unified Modelling Language, CI: continuous integration, SCA: static code analysis](content/images/wall_climbing.png "Wall climbing"){height="700px"}
