## Our experience of development processes involving teams ##

The software development practices that we have adopted can be broadly separated into three categories: 1 - software quality seminars, 2 - code reviews, and 3 - resource sharing.

### Software quality seminars ###
 <!-- I added some structure here, as this section is relatively large -->
Within the framework of software quality seminars, we have established a large-scale knowledge transfer system between the participants.
Presentations and demonstrations of basic concepts, new techniques and tools that are not necessarily tied to a specific project help broaden our knowledge base and awareness.
In this sense, they form almost a substitute for a more formal computer science education, which most bioinformaticians lack [@doi:10.7717/peerj-cs.839].
Through these sessions we built a shared vocabulary that enables quick discussions about implementation details and code structures.
We also gained awareness of packages or technical solutions, which help to improve software performance and quality.

### Code reviews ###
The benefits of code reviews have been reviewed in the past [@doi:10.5334/jors.35; @doi:10.1371/journal.pcbi.1008119; @{https://logicmag.io/clouds/agile-and-the-long-crisis-of-software/}, @ISBN:9780201616224].
This includes fairly obvious things like implementing consistent coding standards, detecting bugs and errors, but also less expected outcomes, such as diverse learning, fostering of a positive environment, or enhancing efficiency.
Prior to a scheduled code review, the author is expected to write their code in a way that it will be explainable and understood by others.
This expectation is largely self-inflicted as each person feel the pressure of exposing their weaknesses - even within a friendly environment.
During the code review, the author has to explain some aspect of their code clearly (e.g. structure, algorithm implementation, performance related decisions).
In our settings, it is entirely up to the author to choose which aspect of the code, or software product to discuss.
Although it is implied that participants of code reviews are intended to discuss implementation details, we accept and enjoy discussions about any other aspect of the code, such as user interface design, documentation, or architecture considerations.

The other participants may not be deeply familiar with the particular project, but they have their unique knowledge and point of view.
The feedback obtained can help fix existing or potential future issues, improve the implementation, and produce cleaner, more concise code.
Our experience indicates a broader adoption of theoretical aspects and good practices of software engineering highlighted during these code review sessions.
We found that during these meetings implicit peer-pressure helps us achieve most goals: standardization of practices, improved code quality, and enhanced usability of the software.

As a positive additional outcome, we noticed an increasing understanding in each other’s projects that naturally emerged through talking about the examined code.
This enabled us to give more involved comments during subsequent group meetings too, where we would naturally discuss each other's scientific projects.
Additionally, seeing and analysing everyone's code on a more hands-on level showed us how repetitive some pieces of code can be in different projects.
This redundancy is partially removed by implementing a system to share resources.

### Resource sharing ###
Resource sharing boils down to making sure that useful resources are brought to the attention of all participants easily.
It can be discussed from two perspectives: external open-access resources (forums, repositories, packages and libraries) and internal (within-group resources with tools).
The latter is very important as it allows for team contribution that can benefit the individual project development.
A simple example of this could be a shared repository of various computational tools that were developed by members of the group.
Such tools are universal enough and fit the group’s research questions, so all people in the group can re-use them.
In addition, each tool can be potentially developed and reviewed by multiple group members.

We believe these three pillars are the minimum requirement for achieving lasting improvement in software development within research teams, but bioinformaticians of other groups should tailor the content and the frequency of these meetings to their specific needs.
Although not explicitly a project conceived during the meetings, many regular attendees have extensively applied many of the discussed software development methods (e.g., object-oriented programming style, user stories when documenting the requirements and assumptions, Jira to add features and report bugs, continuous integration with Git) when working on the same codebase as a team for the latest release of JASPAR database [@doi:10.1093/nar/gkad1059].
We also want to note that this article in fact was successfully written using a continuous integration based tool Manubot [@doi:10.1371/journal.pcbi.1007128].
In the next sections we discuss how software quality seminars and code reviews helped with the examples of three specific software engineering notions: modularization, testing, and dependency management.
We share specific examples from our own projects to highlight how these concepts change the way we code (**Supplementary Figures**).

### Modularization ###

The first example we give is the shift in our work towards increased modularization.
Modular design is one of the most common approach for team programming to ensure maintainability and extensibility of a software product.
We understood from the guidelines and experiences from within the team that moving from unstructured scripts to organized code with functions brings several benefits at a low cost.
Understanding the ways we can improve code organization was a theme we touched several times during the software quality seminars.
In parallel, during code reviews we encountered and discussed several examples where modularization was implemented.
Our toolkit collects stand-alone scripts that are by definition modules to be used.

We covered the following topics in lecture forms to gain understanding in ways to improve modularization (**Supplementary Table 2**): object-oriented programming, class diagrams and unified modelling language in general, design patterns, software architecture, Snakemake [@doi:10.12688/f1000research.29032.1], S4 objects, R package development, a case report from the organization of the JASPAR database project [@doi:10.1093/nar/gkad1059], and a review on the book titled The Pragmatic Programmer [@ISBN:9780135957059].
We understood that modularization can take form in many levels.
On the smallest scale it can mean naming parts of the code by organizing them into functions.
Once a code grew, we can start refactoring into classes and focus on the coherence and coupling of the parts (**Supplementary Figure 1-2**).
When building a pipeline of scripts, we can identify coherent modules that would translate to rules in Snakemake [@doi:10.12688/f1000research.29032.1] (**Supplementary Figure 3-4**.)
To sum up, modularization means the continuous monitoring of the code, the recognition of a code that grew too much, and the re-structuring into smaller parts.
It involves an understanding that the code is not a static entity, but an ever-growing, ever-changing organism.

A recurring question is whether a script needs refactoring or can remain a prototype.
Taschuk and Wilson [@doi:10.1371/journal.pcbi.1005412] suggest a cut-off where a script is being reused, shared with others or used to produce findings in a publication.
This definition would potentially include the majority of code written by bioinformaticians, but the time spent on improving the scripts should be weighed against the time required to deal with suboptimal code on a case-by-case basis.
With practice, and being exposed to lot of code, modularization can become the norm and the distance between a prototype and a refactored code can be significantly reduced.

### Testing ###

As highlighted in the literature [@doi:10.48550/arXiv.1804.01954], testing is a difficult concept for scientific software.
However, it is also a central concept in team programming, as test coverage increases trust and allows the safe addition of new features by any member.
We revisited testing multiple times (**Supplementary Table 2**): discussed debugging tools, how to write unit tests in python (```pytest``` and ```unittest```) and R (```testthat```), what type of functions can be tested, why automated tests are beneficial and how to implement them via continuous integration services (e.g., GitHub Actions).
The main difficulty was for us to see testing as software testing beyond the validation of the scientific feature of the software that can be shown on a small test data.
Similarly to modularization, a recurring question was when to start adding tests.
Although there is no hard threshold, we tend to identify a sweet spot when the code has not grown too much so that refactoring is a daunting task, but also not changing too much so that test coverage would be a wasted effort.
In general, we advise on testing earlier than one would feel like (i.e. departing from the mindset: "I will start tomorrow after I implement this new idea").
Code reviews are a very nice platform to discuss tests: to get the input from peers on how to challenge the implementation.
This part is actually a scientific endeavour, when edge cases can be thought of and the properties of the biological question can be discussed.

### Dependency management ###

Given the large number of dependencies, even whole ecosystems of tools, dependency management is one of the most important task to ensure reproducibility of the findings.
In a team setting, where all members need to be able to run the code, it is natural to create identical environments for all developers.
In the software quality seminars we covered (**Supplementary Table 2**): container solutions [@{https://docs.docker.com/}; @{https://apptainer.org/}], R package development, and Anaconda [@{https://www.anaconda.com/}].
We established the DockerHub account for our group [@{https://hub.docker.com/u/cbgr}] to share our custom containers (**Supplementary Figures**).
This resource also enables easy installation of our Snakemake pipelines across different servers.

In sum, software quality seminars, code reviews and shared resources in the research group can be implemented as separate activities choosing all or any of them.
We observed that even a single activity is benefiting members' coding experience and the resulting code quality.
Overall, as good practices become routine, the required time investment will be reduced and the benefits will become more apparent.
The shared knowledge base and standards also allow us to make new group members adopt good coding practices more quickly.
