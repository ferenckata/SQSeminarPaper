## Our experience of development processes involving teams ##

We can look at the improvement of software writing as an exercise of rock-climbing (**Figure 1**).
At the top of the rock is our goal of good quality software.
Specifically, we identified reliable, performant, and extensible software as our aim, as we wished to improve our skills in creating and maintaining a lasting piece of software as is the scope of our teams [@doi:10.1093/nar/gkad1059 ; @doi:10.1186/s13059-023-02877-1].
In order to reach it, we need to become proficient in the various concepts depicted by the holds.
These concepts were selected from the literature and our professional experience, but are not exhaustive and can be tailored to the specific needs of each group.
The higher they are on the wall, the more advanced we consider the concepts to be.
As the progress is cumulative, we have chosen to show the holds in the same colour if they represent related concepts that build upon each other.
This way, we mimic traditional CS education.
The most important point, however, is the fact that rock climbing requires a partner to belay you, just as we believe the input of other people helps us become better programmers.

The software development practices that we have adopted can be broadly separated into three categories: 1 - software quality seminars, 2 - code reviews, and 3 - resource sharing.
Within the framework of software quality seminars, we have established a large-scale knowledge transfer system between the participants.
Presentations and demonstrations of basic concepts, new techniques and tools that are not necessarily tied to a specific project help broaden our knowledge base and awareness.
In this sense, they form almost a substitute for a more formal computer science education, which most bioinformaticians lack [@doi:10.7717/peerj-cs.839].
Through these sessions we built a shared vocabulary that enables quick discussions about implementation details and code structures.
We also gained awareness of packages or technical solutions, which help to improve software performance and quality.

The benefits of code reviews have been reviewed in the past [@doi:10.5334/jors.35; @doi:10.1371/journal.pcbi.1008119; @{https://logicmag.io/clouds/agile-and-the-long-crisis-of-software/}, @ISBN:9780201616224].
This includes fairly obvious things like implementing consistent coding standards, detecting bugs and errors, but also less expected outcomes, such as diverse learning, fostering of a positive environment or enhancing efficiency.
Prior to a scheduled code review, the author is expected to write their code in a way that it will be explainable and understood by others.
This expectation is largely self-inflicted as each person feel the pressure of exposing their weaknesses - even within a friendly environment.
During the code review, the author has to explain some aspect of their code clearly (e.g. structure, algorithm implementation, performance related decisions).
In our settings, it is entirely up to the author to choose which aspect of the code, or software product to discuss.
Although it is implied that participants of code reviews are intended to discuss implementation details, we accept and enjoy discussions about any other aspect of the code, such as user interface design, documentation, or architecture considerations.
The other participants may not be deeply familiar with the particular project, but they have their unique knowledge and point of view.
The feedback obtained can help fix existing or potential future issues, improve the implementation, and produce cleaner, more concise code.
Our experience indicates a broader adoption of theoretical aspects and good practices of software engineering highlighted during these code review sessions.
We found that during these meetings implicit peer-pressure helps us achieve most goals: standardization of practices, improved code quality, and enhanced usability of the software.
As a positive additional outcome, we noticed an increasing understanding in each other’s projects that naturally emerged through talking about the examined code.
This enabled us to give more involved comments during subsequent group meetings too, where we would naturally discuss each other's scientific projects.
Additionally, seeing and analysing everyone's code on a more hands-on level showed us how repetitive some pieces of code can be in different projects.
This redundancy can be removed by implementing a system to share resources.

Resource sharing boils down to making sure that useful online resources are brought to the attention of all participants easily.
It can be discussed from two perspectives: external open-access resources (forums, repositories, packages and libraries) and internal (within-group resources with tools).
The latter is very important as it allows for team contribution that can benefit the individual project development.
A simple example of this could be a shared repository of various computational tools that were developed by members of the group.
Such tools are universal enough and fit the group’s research questions, so all people in the group can re-use them.
In addition, each tool can be potentially developed and reviewed by multiple group members.

We believe these three pillars are the minimum requirement for achieving lasting improvement in software development within research teams, but bioinformaticians of other groups should tailor the content and the frequency of these meetings to their specific needs.
Although not explicitly a project conceived during the meetings, many regular attendees have extensively applied software quality features (object-oriented programming style, user stories when documenting the requirements and assumptions, Jira to add features and report bugs, continuous integration with Git) when working on the same codebase as a team for the latest release of JASPAR database [@doi:10.1093/nar/gkad1059].
We also want to note that this article in fact was successfully written using a continuous integration based tool Manubot [@doi:10.1371/journal.pcbi.1007128].
In the next sections we discuss how software quality seminars and code reviews helped with the examples of three specific software engineering notions: modularization, testing, and dependency management.

### Modularization ###

The first example we give is the shift in our work towards increased modularization.
We understood from the guidelines and experiences from within the team that moving from unstructured scripts to organized code with functions brings several benefits at a low cost.
Understanding the ways we can improve code organization was a theme we touched several times during the software quality seminars.
In parallel, during code reviews we encountered and discussed several examples where modularization was implemented.
Our toolkit collects stand-alone scripts that are by definition modules to be used.

We covered the following topics in lecture forms to gain understanding in ways to improve modularization: object-oriented programming, class diagrams and unified modelling language in general, design patterns, software architecture, Snakemake [@doi:10.12688/f1000research.29032.1], S4 objects, R package development, a case report from the organization of the JASPAR database project [@doi:10.1093/nar/gkad1059], and a review on the book titled The Pragmatic Programmer [@ISBN:9780135957059].
We understood that modularization can take form in many levels.
On the smallest scale it can mean naming parts of the code by organizing them into functions.
Once a code grew, we can start refactoring into classes and focus on the coherence and coupling of the parts.
When building a pipeline of scripts, we can identify coherent modules that would translate to rules in Snakemake [@doi:10.12688/f1000research.29032.1].
To sum up, modularization means the continuous monitoring of the code, the recognition of a code that grew too much, and the re-structuring into smaller parts.
It involves an understanding that the code is not a static entity, but an ever-growing, ever-changing organism.

In a large distributed project clean coding style may be trivial, but because the bioinformatic projects are often handled by a single person, it is very possible to make the code complex and obfuscated.
We observed in code reviews that during data analysis parts of the code are re-run in an ad-hoc manner (e.g. by commenting out or re-writing parts), making it increasingly difficult to explain the code or reproduce the same analysis.
At the start of implementation of regular meetings, the recurring comments were about modularization, documentation, and variable declarations, until these became standard among the members.
After about half a year, it was established understanding for everyone involved that code organized into functions is preferred over the so-called "spaghetti code".

A recurring question is whether a script needs refactoring or can remain a prototype.
Taschuk and Wilson [@doi:10.1371/journal.pcbi.1005412] suggest a cut-off where a script is being reused, shared with others or used to produce findings in a publication.
This definition would potentially include the majority of code written by bioinformaticians, but the time spent on improving the scripts should be weighed against the time required to deal with suboptimal code.

### Testing ###

As highlighted in the literature [@doi:10.48550/arXiv.1804.01954], testing is a difficult concept for scientific software.
We revisited testing multiple times: discussed debugging tools, how to write unit tests in python (```pytest``` and ```unittest```) and R (```testthat```), what type of functions can be tested, why automated tests are beneficial and how to implement them via continuous integration services (e.g. GitHub Actions).
The main difficulty was for us to see testing as software testing beyond the validation of the scientific feature of the software that can be shown on a small test data.
Similarly to modularization, a recurring question was when to start adding tests.
Although there is no hard threshold, we tend to identify a sweet spot when the code has not grown too much so that refactoring is a daunting task, but also not changing too much so that test coverage would be a wasted effort.
In general, we advise on testing earlier than one would feel like (i.e. I will start tomorrow after I implement this new idea).
Code reviews are a very nice platform to discuss tests: to get the input from peers on how to challenge the implementation.
This part is actually a scientific endeavour, when edge cases can be thought of and the properties of the biological question can be discussed.

### Dependency management ###

Given the large number of dependencies, even whole ecosystems of tools, dependency management is one of the most important task to ensure reproducibility of the findings.
In the software quality seminars we covered: container solutions [@{https://docs.docker.com/}; @{https://apptainer.org/}], R package development, and Anaconda [@doi:https://www.anaconda.com/].
We established the DockerHub account for our group [@{https://hub.docker.com/u/cbgr}] to share our custom containers.
This resource also enables easy installation of our Snakemake pipelines across different servers.

In sum, software quality seminars, code reviews and shared resources in the research group can be implemented as separate activities choosing all or any of them.
We observed that even a single activity is benefiting members' coding experience and the resulting code quality.
Overall, as good practices become routine, the required time investment will be reduced and the benefits will become more apparent.
The shared knowledge base and standards also allow us to make new group members adopt good coding practices more quickly.
